{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Curriculum Learning - Self-Contained\n",
        "\n",
        "Automatic curriculum learning for MiniGrid environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, warnings\n",
        "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from typing import List, Dict\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
        "\n",
        "from src.environment import make_fixed_mixed_vec_env\n",
        "from src.evaluation import evaluate\n",
        "from src.cnn import get_policy_kwargs\n",
        "from src.filemanager import FileManager"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Result directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment directory initialized: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928\n"
          ]
        }
      ],
      "source": [
        "fm: FileManager = FileManager(\"02_curriculum_learning_catastrophic_learning_test\", output_dir=\"results\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Curriculum Teacher\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CurriculumTeacher:\n",
        "    \"\"\"\n",
        "    Simple sequential curriculum:\n",
        "    - Train stage i until recent success >= target\n",
        "    - Then move to next stage\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, stages: List[str], target: float = 0.90, window: int = 5):\n",
        "        self.stages = stages\n",
        "        self.target = target\n",
        "        self.window = window\n",
        "        self.idx = 0\n",
        "        self.performance: Dict[str, List[float]] = {s: [] for s in stages}\n",
        "        self._done = False\n",
        "\n",
        "    def get_env_composition(self) -> Dict[str, int]:\n",
        "        # Check if we should advance\n",
        "        if self._should_advance():\n",
        "            self._advance()\n",
        "\n",
        "        # return the env_name as key with the number 8 as value\n",
        "        return {self.stages[self.idx]: 8}\n",
        "\n",
        "    def record(self, success_rate: float) -> None:\n",
        "        s = self.stages[self.idx]\n",
        "        h = self.performance[s]\n",
        "        h.append(success_rate)\n",
        "        if len(h) > 2000: self.performance[s] = h[-1000:]\n",
        "\n",
        "    # stats\n",
        "    def _mean_recent(self, s: str) -> float:\n",
        "        h = self.performance[s]\n",
        "        if not h: return 0.0\n",
        "        w = min(self.window, len(h))\n",
        "        return float(np.mean(h[-w:]))\n",
        "\n",
        "    # progression rule\n",
        "    def _should_advance(self) -> bool:\n",
        "        s = self.stages[self.idx]\n",
        "        return self._mean_recent(s) >= self.target and len(self.performance[s]) >= self.window\n",
        "\n",
        "    def _advance(self) -> None:\n",
        "        if self.idx < len(self.stages) - 1:\n",
        "            self.idx += 1\n",
        "        else:\n",
        "            self._done = True\n",
        "\n",
        "    # queries\n",
        "    def current_stage(self) -> str:\n",
        "        return self.stages[self.idx]\n",
        "\n",
        "    # stopping\n",
        "    def has_converged_hardest(self, thresh: float = 0.95, evals: int = 3) -> bool:\n",
        "        s = self.stages[-1]\n",
        "        h = self.performance[s]\n",
        "        if len(h) < evals: return False\n",
        "        return float(np.mean(h[-evals:])) >= thresh\n",
        "\n",
        "    def catastrophic_learning(self, under_target: float = 0.1, evals: int = 3) -> bool:\n",
        "        s = self.stages[-1]\n",
        "        h = self.performance[s]\n",
        "        if len(h) < evals: return False\n",
        "        seg = h[-evals:]\n",
        "        return float(np.mean(seg)) < (self.target - under_target)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step Callback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StepCallback(BaseCallback):\n",
        "    \"\"\"Periodic evaluation and entropy management.\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        teacher: CurriculumTeacher,\n",
        "        eval_freq: int = 5_000,\n",
        "        n_eval: int = 30,\n",
        "        visualize: bool = True,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.teacher: CurriculumTeacher = teacher\n",
        "        self.eval_freq: int = eval_freq\n",
        "        self.n_eval: int = n_eval\n",
        "        self.visualize: bool = visualize\n",
        "        self.stage_steps: int = 0\n",
        "        self.total_steps: int = 0\n",
        "        self.training_start_time: float = time.time()\n",
        "        self.stage_start_time: float = time.time()\n",
        "        self.total_training_time: float = 0.0\n",
        "    \n",
        "    def _on_step(self) -> bool:\n",
        "        self.stage_steps += 1\n",
        "        self.total_steps += 1\n",
        "        \n",
        "        if self.stage_steps % self.eval_freq == 0:\n",
        "            assert isinstance(self.model, PPO)\n",
        "            \n",
        "            # Evaluate\n",
        "            episode_batch = evaluate(self.model, self.teacher.current_stage(), self.n_eval)\n",
        "            self.teacher.record(episode_batch.success_rate)\n",
        "            \n",
        "            # Calculate elapsed times\n",
        "            stage_elapsed: float = time.time() - self.stage_start_time\n",
        "            total_elapsed: float = self.get_total_time()\n",
        "            \n",
        "            # Print evaluation results\n",
        "            print(\n",
        "                f\"  Eval @ Stage {self.stage_steps:,} | Total: {self.total_steps:,} | \"\n",
        "                f\"Success: {episode_batch.success_rate:.1%} | \"\n",
        "                f\"Reward: {episode_batch.mean_reward:.2f} | \"\n",
        "                f\"PolicyEnt: {episode_batch.mean_entropy:.3f} | \"\n",
        "                f\"StageTime: {int(stage_elapsed//60):02d}:{int(stage_elapsed%60):02d} | \"\n",
        "                f\"TotalTime: {int(total_elapsed//60):02d}:{int(total_elapsed%60):02d}\"\n",
        "            )\n",
        "            \n",
        "            # Write evaluation\n",
        "            fm.dump_eval_to_csv(\n",
        "                total_step=self.total_steps,\n",
        "                stage=self.teacher.current_stage(),\n",
        "                stage_step=self.stage_steps,\n",
        "                batch=episode_batch,\n",
        "                model=self.model,\n",
        "                allocation={}\n",
        "            )\n",
        "            \n",
        "            # Visualize\n",
        "            if self.visualize:\n",
        "                from src.episode_visualization import visualize_eval_episode\n",
        "                visualize_eval_episode(\n",
        "                    model=self.model,\n",
        "                    episode=episode_batch.episodes[0],\n",
        "                    timestep=self.total_steps,\n",
        "                    output_dir=fm.get_visualization_dir()\n",
        "                )\n",
        "        \n",
        "        return True\n",
        "\n",
        "    \n",
        "    def reset_for_stage(self) -> None:\n",
        "        \"\"\"Reset stage counter and timer for new environment.\"\"\"\n",
        "        # Accumulate time from completed stage\n",
        "        stage_elapsed: float = time.time() - self.stage_start_time\n",
        "        self.total_training_time += stage_elapsed\n",
        "        \n",
        "        # Reset for new stage\n",
        "        self.stage_steps = 0\n",
        "        self.stage_start_time = time.time()\n",
        "    \n",
        "    def get_stage_elapsed(self) -> float:\n",
        "        \"\"\"Get elapsed time for current stage in seconds.\"\"\"\n",
        "        return time.time() - self.stage_start_time\n",
        "    \n",
        "    def get_total_time(self) -> float:\n",
        "        \"\"\"Get total training time across all stages in seconds.\"\"\"\n",
        "        return self.total_training_time + self.get_stage_elapsed()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "N_ENVS: int = 8\n",
        "N_STEPS: int = 128\n",
        "STEPS_PER_ROLLOUT = N_STEPS * N_ENVS\n",
        "\n",
        "# Evaluate every 5 rollout\n",
        "EVAL_FREQ: int = 3 * STEPS_PER_ROLLOUT\n",
        "N_EVALS: int = 100\n",
        "\n",
        "device = \"\"\n",
        "if torch.cuda.is_available(): # type: ignore\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Curriculum\n",
        "THRESHOLD: float = 0.90\n",
        "WINDOW: int = 3\n",
        "\n",
        "# https://minigrid.farama.org/environments/minigrid/\n",
        "\n",
        "STAGES: List[str] = [\n",
        "    \"MiniGrid-DoorKey-5x5-v0\",\n",
        "    \"MiniGrid-DoorKey-6x6-v0\",\n",
        "    \"MiniGrid-DoorKey-8x8-v0\",\n",
        "    \"MiniGrid-DoorKey-16x16-v0\",\n",
        "]\n",
        "\n",
        "\n",
        "TOTAL_STEPS: int = 100_000\n",
        "\n",
        "# PPO\n",
        "def make_model(env: SubprocVecEnv) -> PPO:\n",
        "    return PPO(\n",
        "        \"CnnPolicy\",\n",
        "        env,\n",
        "        policy_kwargs=get_policy_kwargs(),\n",
        "        learning_rate= 3e-4,\n",
        "        n_steps=N_STEPS,\n",
        "        batch_size=64,\n",
        "        n_epochs=10,\n",
        "        gamma=0.99,\n",
        "        gae_lambda=0.95,\n",
        "        clip_range=0.2,\n",
        "        ent_coef=0.02,\n",
        "        verbose=0,\n",
        "        device=device\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_curriculum() -> None:\n",
        "    \"\"\"Train with sequential curriculum.\"\"\"\n",
        "    \n",
        "    teacher = CurriculumTeacher(\n",
        "        STAGES,\n",
        "        target=THRESHOLD,\n",
        "        window=WINDOW,  \n",
        "    )\n",
        "\n",
        "    callback = StepCallback(\n",
        "        teacher,\n",
        "        eval_freq=EVAL_FREQ,\n",
        "        n_eval=N_EVALS,\n",
        "        visualize=True,\n",
        "    )\n",
        "\n",
        "    # Initial allocation + initial env/model\n",
        "    allocation = teacher.get_env_composition()\n",
        "    env = make_fixed_mixed_vec_env(allocation)\n",
        "    model = make_model(env)\n",
        "\n",
        "    print(f\"\\n=== Initial Allocation: {allocation} ===\")\n",
        "\n",
        "    while (\n",
        "        callback.total_steps < TOTAL_STEPS \n",
        "        and not teacher.has_converged_hardest(thresh=0.9, evals=3)\n",
        "        and not teacher.catastrophic_learning(under_target=0.1, evals=3)\n",
        "    ):\n",
        "\n",
        "        # Train for eval_freq steps (callback does evaluations)\n",
        "        model.learn( # type: ignore\n",
        "            total_timesteps=EVAL_FREQ,\n",
        "            callback=callback,\n",
        "            reset_num_timesteps=False\n",
        "        )\n",
        "\n",
        "        # Recompute curriculum allocation\n",
        "        new_alloc = teacher.get_env_composition()\n",
        "\n",
        "        # If allocation changed -> recompose VecEnv\n",
        "        if new_alloc != allocation:\n",
        "            print(f\"\\n>>> Curriculum shift detected\")\n",
        "            print(f\"    Old: {allocation}\")\n",
        "            print(f\"    New: {new_alloc}\\n\")\n",
        "\n",
        "            env.close()\n",
        "            env = make_fixed_mixed_vec_env(new_alloc)\n",
        "            model.set_env(env) # type: ignore\n",
        "            allocation = new_alloc\n",
        "\n",
        "            fm.save_checkpoint(\n",
        "                model=model,\n",
        "                stage=f\"auto_stage\",\n",
        "                total_step=callback.total_steps\n",
        "            )\n",
        "\n",
        "    env.close()\n",
        "\n",
        "    total_time = time.time() - callback.training_start_time\n",
        "    print(f\"\\n=== TRAINING COMPLETE ===\")\n",
        "    print(f\"Time: {int(total_time//60):02d}:{int(total_time%60):02d}\")\n",
        "    print(f\"Steps: {callback.total_steps:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Initial Allocation: {'MiniGrid-DoorKey-5x5-v0': 8} ===\n",
            "  Eval @ Stage 3,072 | Total: 3,072 | Success: 17.0% | Reward: 0.08 | PolicyEnt: 1.690 | StageTime: 01:41 | TotalTime: 01:41\n",
            "    → Evaluation saved to: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/evaluations.csv\n",
            "    → Saved visualization: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/visualizations/eval_3072_MiniGrid_DoorKey_5x5_v0.png\n",
            "  Eval @ Stage 6,144 | Total: 6,144 | Success: 100.0% | Reward: 0.95 | PolicyEnt: 0.673 | StageTime: 02:21 | TotalTime: 02:21\n",
            "    → Evaluation saved to: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/evaluations.csv\n",
            "    → Saved visualization: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/visualizations/eval_6144_MiniGrid_DoorKey_5x5_v0.png\n",
            "  Eval @ Stage 9,216 | Total: 9,216 | Success: 100.0% | Reward: 0.96 | PolicyEnt: 0.147 | StageTime: 03:05 | TotalTime: 03:05\n",
            "    → Evaluation saved to: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/evaluations.csv\n",
            "    → Saved visualization: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/visualizations/eval_9216_MiniGrid_DoorKey_5x5_v0.png\n",
            "  Eval @ Stage 12,288 | Total: 12,288 | Success: 100.0% | Reward: 0.96 | PolicyEnt: 0.280 | StageTime: 03:48 | TotalTime: 03:48\n",
            "    → Evaluation saved to: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/evaluations.csv\n",
            "    → Saved visualization: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/visualizations/eval_12288_MiniGrid_DoorKey_5x5_v0.png\n",
            "\n",
            ">>> Curriculum shift detected\n",
            "    Old: {'MiniGrid-DoorKey-5x5-v0': 8}\n",
            "    New: {'MiniGrid-DoorKey-6x6-v0': 8}\n",
            "\n",
            "    → Checkpoint saved: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/checkpoints/auto_stage_step_12288.zip\n",
            "  Eval @ Stage 15,360 | Total: 15,360 | Success: 69.0% | Reward: 0.60 | PolicyEnt: 0.876 | StageTime: 05:21 | TotalTime: 05:21\n",
            "    → Evaluation saved to: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/evaluations.csv\n",
            "    → Saved visualization: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/visualizations/eval_15360_MiniGrid_DoorKey_6x6_v0.png\n",
            "  Eval @ Stage 18,432 | Total: 18,432 | Success: 100.0% | Reward: 0.96 | PolicyEnt: 0.350 | StageTime: 06:04 | TotalTime: 06:04\n",
            "    → Evaluation saved to: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/evaluations.csv\n",
            "    → Saved visualization: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/visualizations/eval_18432_MiniGrid_DoorKey_6x6_v0.png\n",
            "  Eval @ Stage 21,504 | Total: 21,504 | Success: 100.0% | Reward: 0.96 | PolicyEnt: 0.231 | StageTime: 06:48 | TotalTime: 06:48\n",
            "    → Evaluation saved to: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/evaluations.csv\n",
            "    → Saved visualization: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/visualizations/eval_21504_MiniGrid_DoorKey_6x6_v0.png\n",
            "  Eval @ Stage 24,576 | Total: 24,576 | Success: 100.0% | Reward: 0.96 | PolicyEnt: 0.208 | StageTime: 07:35 | TotalTime: 07:35\n",
            "    → Evaluation saved to: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/evaluations.csv\n",
            "    → Saved visualization: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/visualizations/eval_24576_MiniGrid_DoorKey_6x6_v0.png\n",
            "\n",
            ">>> Curriculum shift detected\n",
            "    Old: {'MiniGrid-DoorKey-6x6-v0': 8}\n",
            "    New: {'MiniGrid-DoorKey-8x8-v0': 8}\n",
            "\n",
            "    → Checkpoint saved: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/checkpoints/auto_stage_step_24576.zip\n",
            "  Eval @ Stage 27,648 | Total: 27,648 | Success: 100.0% | Reward: 0.94 | PolicyEnt: 0.631 | StageTime: 08:27 | TotalTime: 08:27\n",
            "    → Evaluation saved to: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/evaluations.csv\n",
            "    → Saved visualization: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/visualizations/eval_27648_MiniGrid_DoorKey_8x8_v0.png\n",
            "  Eval @ Stage 30,720 | Total: 30,720 | Success: 100.0% | Reward: 0.96 | PolicyEnt: 0.327 | StageTime: 09:10 | TotalTime: 09:10\n",
            "    → Evaluation saved to: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/evaluations.csv\n",
            "    → Saved visualization: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/visualizations/eval_30720_MiniGrid_DoorKey_8x8_v0.png\n",
            "  Eval @ Stage 33,792 | Total: 33,792 | Success: 100.0% | Reward: 0.96 | PolicyEnt: 0.383 | StageTime: 09:53 | TotalTime: 09:53\n",
            "    → Evaluation saved to: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/evaluations.csv\n",
            "    → Saved visualization: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/visualizations/eval_33792_MiniGrid_DoorKey_8x8_v0.png\n",
            "\n",
            ">>> Curriculum shift detected\n",
            "    Old: {'MiniGrid-DoorKey-8x8-v0': 8}\n",
            "    New: {'MiniGrid-DoorKey-16x16-v0': 8}\n",
            "\n",
            "    → Checkpoint saved: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/checkpoints/auto_stage_step_33792.zip\n",
            "  Eval @ Stage 36,864 | Total: 36,864 | Success: 99.0% | Reward: 0.89 | PolicyEnt: 0.844 | StageTime: 11:56 | TotalTime: 11:56\n",
            "    → Evaluation saved to: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/evaluations.csv\n",
            "    → Saved visualization: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/visualizations/eval_36864_MiniGrid_DoorKey_16x16_v0.png\n",
            "  Eval @ Stage 39,936 | Total: 39,936 | Success: 98.0% | Reward: 0.90 | PolicyEnt: 0.780 | StageTime: 13:40 | TotalTime: 13:40\n",
            "    → Evaluation saved to: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/evaluations.csv\n",
            "    → Saved visualization: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/visualizations/eval_39936_MiniGrid_DoorKey_16x16_v0.png\n",
            "  Eval @ Stage 43,008 | Total: 43,008 | Success: 62.0% | Reward: 0.42 | PolicyEnt: 1.304 | StageTime: 21:05 | TotalTime: 21:05\n",
            "    → Evaluation saved to: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/evaluations.csv\n",
            "    → Saved visualization: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/visualizations/eval_43008_MiniGrid_DoorKey_16x16_v0.png\n",
            "  Eval @ Stage 46,080 | Total: 46,080 | Success: 37.0% | Reward: 0.21 | PolicyEnt: 1.552 | StageTime: 31:46 | TotalTime: 31:46\n",
            "    → Evaluation saved to: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/evaluations.csv\n",
            "    → Saved visualization: results/02_curriculum_learning_catastrophic_learning_test_20251031_222928/visualizations/eval_46080_MiniGrid_DoorKey_16x16_v0.png\n",
            "\n",
            "=== TRAINING COMPLETE ===\n",
            "Time: 31:56\n",
            "Steps: 46,080\n"
          ]
        }
      ],
      "source": [
        "train_curriculum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from src.environment import run_episode\n",
        "# model_path = \"results/01_curriculum_learning_catastrophic_learning_test_20251031_222928/checkpoints/auto_stage_step_33792.zip\"\n",
        "# model = PPO.load(model_path) # type: ignore\n",
        "# episode_data = run_episode(\n",
        "#     model=model, \n",
        "#     env_name=\"MiniGrid-DoorKey-16x16-v0\", \n",
        "#     seed=42, \n",
        "#     render_mode=\"human\", \n",
        "#     deterministic=True\n",
        "# )\n",
        "\n",
        "# print(episode_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from src.episode_visualization import visualize_eval_episode\n",
        "# visualize_eval_episode(\n",
        "#     model=model,\n",
        "#     episode=episode_data,\n",
        "#     timestep=-1,\n",
        "#     output_dir=\"./\"\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
